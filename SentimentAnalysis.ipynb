{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2ebfb68-d24e-42e4-820c-e6b76fff0c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  y\n",
      "0  So there is no way for me to plug it in here i...  0\n",
      "1                        Good case, Excellent value.  1\n",
      "2                             Great for the jawbone.  1\n",
      "3  Tied to charger for conversations lasting more...  0\n",
      "4                                  The mic is great.  1 \n",
      "Class balance:\n",
      " y\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "=== RESULTS (5-fold CV Accuracy) ===\n",
      "COUNT unigrams     : mean=0.787, std=0.020, scores=[0.79  0.75  0.8   0.81  0.785]\n",
      "INDICATOR unigrams : mean=0.789, std=0.022, scores=[0.785 0.755 0.81  0.815 0.78 ]\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Compare COUNT unigrams vs INDICATOR (binary) unigrams\n",
    "# with: stemming, stopword removal, lowercasing, punctuation removal,\n",
    "# min frequency threshold = 5, unigrams only, + number-of-words feature,\n",
    "# RandomForest (defaults), using cross-validation.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Load data\n",
    "# -----------------------------\n",
    "# Expected format (UCI \"sentiment labelled sentences\"):\n",
    "# each line: \"review text<TAB>label\"\n",
    "# label: 0 or 1\n",
    "\n",
    "DATA_PATH = \"amazon_cells_labelled.txt\"   # change if needed\n",
    "\n",
    "texts = []\n",
    "labels = []\n",
    "with open(DATA_PATH, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split(\"\\t\")\n",
    "        if len(parts) != 2:\n",
    "            continue\n",
    "        text, lab = parts\n",
    "        texts.append(text)\n",
    "        labels.append(int(lab))\n",
    "\n",
    "df = pd.DataFrame({\"text\": texts, \"y\": labels})\n",
    "print(df.head(), \"\\nClass balance:\\n\", df[\"y\"].value_counts(normalize=True))\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Preprocessing helpers\n",
    "# -----------------------------\n",
    "# We'll implement:\n",
    "# - lowercasing\n",
    "# - remove punctuation\n",
    "# - tokenize\n",
    "# - remove stopwords\n",
    "# - stemming\n",
    "#\n",
    "# We'll build a custom analyzer for CountVectorizer.\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# If you haven't downloaded these before, uncomment:\n",
    "# nltk.download(\"stopwords\")\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "STEMMER = PorterStemmer()\n",
    "\n",
    "TOKEN_RE = re.compile(r\"[A-Za-z]+\")\n",
    "\n",
    "def stem_analyzer(doc: str):\n",
    "    doc = doc.lower()\n",
    "    # keep only word-like tokens (removes punctuation/numbers)\n",
    "    tokens = TOKEN_RE.findall(doc)\n",
    "    # stopword removal + stemming\n",
    "    return [STEMMER.stem(t) for t in tokens if t not in STOPWORDS]\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Number-of-words feature transformer\n",
    "# -----------------------------\n",
    "class WordCountTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Returns a (n_samples, 1) array = number of tokens in the processed text.\"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        counts = []\n",
    "        for doc in X:\n",
    "            tokens = stem_analyzer(doc)\n",
    "            counts.append(len(tokens))\n",
    "        return np.array(counts).reshape(-1, 1)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Build two feature pipelines\n",
    "# -----------------------------\n",
    "def make_model(binary: bool):\n",
    "    \"\"\"\n",
    "    binary=False => count unigrams\n",
    "    binary=True  => indicator unigrams\n",
    "    \"\"\"\n",
    "    text_vectorizer = CountVectorizer(\n",
    "        analyzer=stem_analyzer,\n",
    "        ngram_range=(1, 1),  # unigrams only\n",
    "        min_df=1,            # threshold = 5\n",
    "        binary=binary\n",
    "    )\n",
    "\n",
    "    # ColumnTransformer to combine:\n",
    "    # - sparse unigram matrix from df[\"text\"]\n",
    "    # - dense word-count feature from df[\"text\"]\n",
    "    features = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"unigrams\", text_vectorizer, \"text\"),\n",
    "            (\"n_words\", WordCountTransformer(), \"text\")\n",
    "        ],\n",
    "        remainder=\"drop\",\n",
    "        sparse_threshold=0.3\n",
    "    )\n",
    "\n",
    "    clf = RandomForestClassifier(random_state=42)  # defaults otherwise\n",
    "\n",
    "    return Pipeline([\n",
    "        (\"features\", features),\n",
    "        (\"rf\", clf)\n",
    "    ])\n",
    "\n",
    "count_model = make_model(binary=False)\n",
    "indicator_model = make_model(binary=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Evaluate with cross-validation\n",
    "# -----------------------------\n",
    "X = df[[\"text\"]]\n",
    "y = df[\"y\"].values\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "count_scores = cross_val_score(count_model, X, y, cv=cv, scoring=\"accuracy\")\n",
    "ind_scores   = cross_val_score(indicator_model, X, y, cv=cv, scoring=\"accuracy\")\n",
    "\n",
    "print(\"\\n=== RESULTS (5-fold CV Accuracy) ===\")\n",
    "print(f\"COUNT unigrams     : mean={count_scores.mean():.3f}, std={count_scores.std():.3f}, scores={np.round(count_scores,3)}\")\n",
    "print(f\"INDICATOR unigrams : mean={ind_scores.mean():.3f}, std={ind_scores.std():.3f}, scores={np.round(ind_scores,3)}\")\n",
    "\n",
    "# Optional: fit on full data if you want a final model\n",
    "# count_model.fit(X, y)\n",
    "# indicator_model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84368d35-eba2-4369-a5ea-4cc93fb364f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
